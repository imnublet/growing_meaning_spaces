{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "318a16ca-74bf-4bd7-af7c-bf6ca56ca375",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (7.7.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (6.9.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (8.0.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.2.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (1.1.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (3.6.0)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.4)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.1.2)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (59.5.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: black in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (22.1.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.26)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (4.9.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.3)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (4.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (5.4.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (23.1.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (3.7.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.8/site-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.4.1)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.4.2)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.13.1)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.9.0)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.3.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.3)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=4.0.0->ipywidgets) (0.9.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=4.0.0->ipywidgets) (0.4.3)\n",
      "Requirement already satisfied: platformdirs>=2 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=4.0.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=4.0.0->ipywidgets) (4.0.1)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=4.0.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=4.0.0->ipywidgets) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.11)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.3)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.7)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: executing in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: asttokens in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (2.0.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting git+https://github.com/facebookresearch/EGG.git\n",
      "  Cloning https://github.com/facebookresearch/EGG.git to /tmp/pip-req-build-ivll0upe\n",
      "  Running command git clone -q https://github.com/facebookresearch/EGG.git /tmp/pip-req-build-ivll0upe\n",
      "  Resolved https://github.com/facebookresearch/EGG.git to commit 18d72d86cf9706e7ad82f94719b56accd288e59a\n",
      "Requirement already satisfied: torch>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from EGG==0.1.0) (1.11.0a0+17540c5)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.8/site-packages (from EGG==0.1.0) (0.12.0a0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from EGG==0.1.0) (1.6.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from EGG==0.1.0) (1.22.2)\n",
      "Requirement already satisfied: pytest in /opt/conda/lib/python3.8/site-packages (from EGG==0.1.0) (6.2.5)\n",
      "Requirement already satisfied: editdistance in /opt/conda/lib/python3.8/site-packages (from EGG==0.1.0) (0.6.2)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.8/site-packages (from EGG==0.1.0) (0.8)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.8/site-packages (from EGG==0.1.0) (13.5.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.8/site-packages (from EGG==0.1.0) (0.24.0)\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.8/site-packages (from EGG==0.1.0) (0.15.8)\n",
      "Requirement already satisfied: submitit in /opt/conda/lib/python3.8/site-packages (from EGG==0.1.0) (1.4.5)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.1.0->EGG==0.1.0) (4.0.1)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/lib/python3.8/site-packages (from pytest->EGG==0.1.0) (1.0.0)\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.8/site-packages (from pytest->EGG==0.1.0) (1.1.1)\n",
      "Requirement already satisfied: py>=1.8.2 in /opt/conda/lib/python3.8/site-packages (from pytest->EGG==0.1.0) (1.11.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from pytest->EGG==0.1.0) (21.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.8/site-packages (from pytest->EGG==0.1.0) (23.1.0)\n",
      "Requirement already satisfied: toml in /opt/conda/lib/python3.8/site-packages (from pytest->EGG==0.1.0) (0.10.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->pytest->EGG==0.1.0) (3.0.7)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.8/site-packages (from rich->EGG==0.1.0) (2.16.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.8/site-packages (from rich->EGG==0.1.0) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich->EGG==0.1.0) (0.1.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->EGG==0.1.0) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->EGG==0.1.0) (3.1.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.1 in /opt/conda/lib/python3.8/site-packages (from submitit->EGG==0.1.0) (2.0.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.8/site-packages (from torchvision->EGG==0.1.0) (9.0.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from torchvision->EGG==0.1.0) (2.26.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->EGG==0.1.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->EGG==0.1.0) (1.26.16)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->EGG==0.1.0) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->EGG==0.1.0) (2.0.9)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb->EGG==0.1.0) (1.29.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb->EGG==0.1.0) (5.9.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.8/site-packages (from wandb->EGG==0.1.0) (1.4.4)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.8/site-packages (from wandb->EGG==0.1.0) (0.1.2)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.8/site-packages (from wandb->EGG==0.1.0) (5.4.1)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.8/site-packages (from wandb->EGG==0.1.0) (1.3.2)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.8/site-packages (from wandb->EGG==0.1.0) (8.0.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /opt/conda/lib/python3.8/site-packages (from wandb->EGG==0.1.0) (3.19.4)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb->EGG==0.1.0) (3.1.32)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.8/site-packages (from wandb->EGG==0.1.0) (0.4.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from wandb->EGG==0.1.0) (59.5.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from docker-pycreds>=0.4.0->wandb->EGG==0.1.0) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.8/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb->EGG==0.1.0) (4.0.10)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->EGG==0.1.0) (5.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets\n",
    "!pip install git+https://github.com/facebookresearch/EGG.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6729903b-f054-4499-b465-f0f0d3fde587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "from functools import reduce\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import egg.core as core\n",
    "from egg.zoo.objects_game.util import compute_binomial\n",
    "from egg.core import language_analysis\n",
    "\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils import data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "from torch import tensor\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 5, 10\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import operator\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "\n",
    "import egg.core as core\n",
    "from egg.core.util import move_to\n",
    "from egg.zoo.objects_game.archs import Receiver, Sender\n",
    "# from archs import Receiver, Sender\n",
    "from egg.zoo.objects_game.features import VectorsLoader\n",
    "from egg.zoo.objects_game.util import (\n",
    "    compute_baseline_accuracy,\n",
    "    compute_mi_input_msgs,\n",
    "    dump_sender_receiver,\n",
    "    entropy,\n",
    "    mutual_info,\n",
    ")\n",
    "\n",
    "# For convenince and reproducibility, we set some EGG-level command line arguments here\n",
    "opts = core.init(params=['--random_seed=7', # will initialize numpy, torch, and python RNGs\n",
    "                         '--lr=1e-3',   # sets the learning rate for the selected optimizer \n",
    "                         '--batch_size=32',\n",
    "                         '--optimizer=adam'])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce5ea891-2ad2-4d5e-be5a-9e25f9128c59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_params(params):\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    input_data = parser.add_mutually_exclusive_group()\n",
    "    input_data.add_argument(\n",
    "        \"--perceptual_dimensions\",\n",
    "        type=str,\n",
    "        default=\"[5, 5, 5, 5, 5]\",\n",
    "        help=\"Number of features for every perceptual dimension\",\n",
    "    )\n",
    "    input_data.add_argument(\n",
    "        \"--load_data_path\",\n",
    "        type=str,\n",
    "        help=\"Path to .npz data file to load\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--n_distractors\",\n",
    "        type=int,\n",
    "        default=3,\n",
    "        help=\"Number of distractor objects for the receiver (default: 3)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--train_samples\",\n",
    "        type=float,\n",
    "        default=128000,\n",
    "        help=\"Number of tuples in training data (default: 1e6)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--validation_samples\",\n",
    "        type=float,\n",
    "        default=16000,\n",
    "        help=\"Number of tuples in validation data (default: 1e4)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--test_samples\",\n",
    "        type=float,\n",
    "        default=4000,\n",
    "        help=\"Number of tuples in test data (default: 1e3)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data_seed\",\n",
    "        type=int,\n",
    "        default=111,\n",
    "        help=\"Seed for random creation of train, validation and test tuples (default: 111)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--shuffle_train_data\",\n",
    "        action=\"store_true\",\n",
    "        default=True,\n",
    "        help=\"Shuffle train data before every epoch (default: False)\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--sender_hidden\",\n",
    "        type=int,\n",
    "        default=50,\n",
    "        help=\"Size of the hidden layer of Sender (default: 50)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--receiver_hidden\",\n",
    "        type=int,\n",
    "        default=50,\n",
    "        help=\"Size of the hidden layer of Receiver (default: 50)\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--sender_embedding\",\n",
    "        type=int,\n",
    "        default=10,\n",
    "        help=\"Dimensionality of the embedding hidden layer for Sender (default: 10)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--receiver_embedding\",\n",
    "        type=int,\n",
    "        default=10,\n",
    "        help=\"Dimensionality of the embedding hidden layer for Receiver (default: 10)\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--sender_cell\",\n",
    "        type=str,\n",
    "        default=\"gru\",\n",
    "        help=\"Type of the cell used for Sender {rnn, gru, lstm} (default: rnn)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--receiver_cell\",\n",
    "        type=str,\n",
    "        default=\"gru\",\n",
    "        help=\"Type of the cell used for Receiver {rnn, gru, lstm} (default: rnn)\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--sender_lr\",\n",
    "        type=float,\n",
    "        default=0.001,\n",
    "        help=\"Learning rate for Sender's parameters (default: 1e-1)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--receiver_lr\",\n",
    "        type=float,\n",
    "        default=0.001,\n",
    "        help=\"Learning rate for Receiver's parameters (default: 1e-1)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--temperature\",\n",
    "        type=float,\n",
    "        default=1,\n",
    "        help=\"GS temperature for the sender (default: 1.0)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--mode\",\n",
    "        type=str,\n",
    "        default=\"gs\",\n",
    "        help=\"Selects whether Reinforce or GumbelSoftmax relaxation is used for training {gs only at the moment}\"\n",
    "        \"(default: rf)\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--output_json\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"If set, egg will output validation stats in json format (default: False)\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--evaluate\",\n",
    "        action=\"store_true\",\n",
    "        default=True,\n",
    "        help=\"Evaluate trained model on test data\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--dump_data_folder\",\n",
    "        type=str,\n",
    "        default='./dump_data/',\n",
    "        help=\"Folder where file with dumped data will be created\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--dump_msg_folder\",\n",
    "        type=str,\n",
    "        default=None,\n",
    "        help=\"Folder where file with dumped messages will be created\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--debug\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"Run egg/objects_game with pdb enabled\",\n",
    "    )\n",
    "    \n",
    "\n",
    "    args = core.init(parser, params)\n",
    "\n",
    "    check_args(args)\n",
    "\n",
    "    return args\n",
    "\n",
    "def check_args(args):\n",
    "    args.train_samples, args.validation_samples, args.test_samples = (\n",
    "        int(args.train_samples),\n",
    "        int(args.validation_samples),\n",
    "        int(args.test_samples),\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        args.perceptual_dimensions = eval(args.perceptual_dimensions)\n",
    "    except SyntaxError:\n",
    "        print(\n",
    "            \"The format of the # of perceptual dimensions param is not correct. Please change it to string representing a list of int. Correct format: '[int, ..., int]' \"\n",
    "        )\n",
    "        exit(1)\n",
    "\n",
    "    if args.debug:\n",
    "        import pdb\n",
    "\n",
    "        pdb.set_trace()\n",
    "\n",
    "    args.n_features = len(args.perceptual_dimensions)\n",
    "    print(args.perceptual_dimensions)\n",
    "\n",
    "    # can't set data loading and data dumping at the same time\n",
    "    assert not (\n",
    "        args.load_data_path and args.dump_data_folder\n",
    "    ), \"Cannot set folder to dump data while setting path to vectors to be loaded. Are you trying to dump the same vectors that you are loading?\"\n",
    "\n",
    "    args.dump_msg_folder = (\n",
    "        pathlib.Path(args.dump_msg_folder) if args.dump_msg_folder is not None else None\n",
    "    )\n",
    "\n",
    "    if (not args.evaluate) and args.dump_msg_folder:\n",
    "        print(\n",
    "            \"| WARNING --dump_msg_folder was set without --evaluate. Evaluation will not be performed nor any results will be dumped. Please set --evaluate\"\n",
    "        )\n",
    "\n",
    "\n",
    "def loss(\n",
    "    _sender_input, _message, _receiver_input, receiver_output, _labels, _aux_input\n",
    "):\n",
    "    acc = (receiver_output.argmax(dim=1) == _labels).detach().float()\n",
    "    loss = F.cross_entropy(receiver_output, _labels, reduction=\"none\")\n",
    "    return loss, {\"acc\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee17f3bf-6151-4c56-b640-85f3504af585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(params, symbol_size, start=True):\n",
    "    listener_path = './models/listener.pt'\n",
    "    speaker_path = './models/speaker.pt'\n",
    "    opts = get_params(params)\n",
    "\n",
    "    ########################################################\n",
    "    device = torch.device(\"cuda\")  # Uncomment this\n",
    "    random.seed(None)\n",
    "    randseed = random.randrange(1, 10000)\n",
    "    print('randseed:', randseed)\n",
    "    ########################################################\n",
    "\n",
    "    data_loader = VectorsLoader(\n",
    "        perceptual_dimensions=opts.perceptual_dimensions,\n",
    "        n_distractors=opts.n_distractors,\n",
    "        batch_size=opts.batch_size,\n",
    "        train_samples=opts.train_samples,\n",
    "        validation_samples=opts.validation_samples,\n",
    "        test_samples=opts.test_samples,\n",
    "        shuffle_train_data=opts.shuffle_train_data,\n",
    "        dump_data_folder=opts.dump_data_folder,\n",
    "        load_data_path=opts.load_data_path,\n",
    "        seed=randseed,\n",
    "    )\n",
    "\n",
    "    train_data, validation_data, test_data = data_loader.get_iterators()\n",
    "\n",
    "    data_loader.upd_cl_options(opts)\n",
    "\n",
    "    if opts.max_len > 1:\n",
    "        baseline_msg = 'Cannot yet compute \"smart\" baseline value for messages of length greater than 1'\n",
    "    else:\n",
    "        baseline_msg = (\n",
    "            f\"\\n| Baselines measures with {opts.n_distractors} distractors and messages of max_len = {opts.max_len}:\\n\"\n",
    "            f\"| Dummy random baseline: accuracy = {1 / (opts.n_distractors + 1)}\\n\"\n",
    "        )\n",
    "        if -1 not in opts.perceptual_dimensions:\n",
    "            baseline_msg += f'| \"Smart\" baseline with perceptual_dimensions {opts.perceptual_dimensions} = {compute_baseline_accuracy(opts.n_distractors, opts.max_len, *opts.perceptual_dimensions)}\\n'\n",
    "        else:\n",
    "            baseline_msg += f'| Data was loaded froman external file, thus no perceptual_dimension vector was provided, \"smart baseline\" cannot be computed\\n'\n",
    "\n",
    "    print(baseline_msg)\n",
    "\n",
    "    # If there is no sender, initialize a new sender\n",
    "    # Else load an existing state dict into the sender module\n",
    "    sender = Sender(\n",
    "        n_features=data_loader.n_features, n_hidden=opts.sender_hidden\n",
    "    )\n",
    "\n",
    "    receiver = Receiver(\n",
    "        n_features=data_loader.n_features, linear_units=opts.receiver_hidden\n",
    "    )\n",
    "\n",
    "    if not start:\n",
    "        print('loading model for speaker')\n",
    "        sender_dict = load_model(sender, speaker_path)\n",
    "        sender.load_state_dict(sender_dict)\n",
    "        print('loading model for listener')\n",
    "        receiver_dict = load_model(receiver, listener_path)\n",
    "        receiver.load_state_dict(receiver_dict)\n",
    "\n",
    "    if opts.mode.lower() == \"gs\":\n",
    "        sender = core.RnnSenderGS(\n",
    "            sender,\n",
    "            opts.vocab_size,\n",
    "            opts.sender_embedding,\n",
    "            opts.sender_hidden,\n",
    "            cell=opts.sender_cell,\n",
    "            max_len=symbol_size,\n",
    "            temperature=opts.temperature,\n",
    "        )\n",
    "\n",
    "        receiver = core.RnnReceiverGS(\n",
    "            receiver,\n",
    "            opts.vocab_size,\n",
    "            opts.receiver_embedding,\n",
    "            opts.receiver_hidden,\n",
    "            cell=opts.receiver_cell,\n",
    "        )\n",
    "\n",
    "        game = core.SenderReceiverRnnGS(sender, receiver, loss)\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Unknown training mode, {opts.mode}\")\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        [\n",
    "            {\"params\": game.sender.parameters(), \"lr\": opts.sender_lr},\n",
    "            {\"params\": game.receiver.parameters(), \"lr\": opts.receiver_lr},\n",
    "        ]\n",
    "    )\n",
    "    callbacks = [core.ConsoleLogger(as_json=True), core.InteractionSaver()]\n",
    "    if opts.mode.lower() == \"gs\":\n",
    "        callbacks.append(core.TemperatureUpdater(agent=sender, decay=0.9, minimum=0.1))\n",
    "    trainer = core.Trainer(\n",
    "        game=game,\n",
    "        optimizer=optimizer,\n",
    "        train_data=train_data,\n",
    "        validation_data=validation_data,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "\n",
    "    trainer.train(n_epochs=opts.n_epochs)\n",
    "        \n",
    "    if opts.evaluate:\n",
    "        is_gs = opts.mode == \"gs\"\n",
    "        (\n",
    "            sender_inputs,\n",
    "            messages,\n",
    "            receiver_inputs,\n",
    "            receiver_outputs,\n",
    "            labels,\n",
    "        ) = dump_sender_receiver(\n",
    "            game, test_data, is_gs, variable_length=True, device=device\n",
    "        )\n",
    "\n",
    "        receiver_outputs = move_to(receiver_outputs, device)\n",
    "        labels = move_to(labels, device)\n",
    "\n",
    "        receiver_outputs = torch.stack(receiver_outputs)\n",
    "        labels = torch.stack(labels)\n",
    "\n",
    "        tensor_accuracy = receiver_outputs.argmax(dim=1) == labels\n",
    "        accuracy = torch.mean(tensor_accuracy.float()).item()\n",
    "\n",
    "        unique_dict = {}\n",
    "\n",
    "        for elem in sender_inputs:\n",
    "            target = \"\"\n",
    "            for dim in elem:\n",
    "                target += f\"{str(int(dim.item()))}-\"\n",
    "            target = target[:-1]\n",
    "            if target not in unique_dict:\n",
    "                unique_dict[target] = True\n",
    "\n",
    "        print(f\"| Accuracy on test set: {accuracy}\")\n",
    "\n",
    "        compute_mi_input_msgs(sender_inputs, messages)\n",
    "        analysis = language_analysis.Disent(False, compute_bosdis=True, compute_posdis=True, vocab_size=vocab_size)\n",
    "        textfile = open(\"out.txt\", \"w\")\n",
    "        for i, msg in enumerate(messages):\n",
    "            while (len(messages[i]) <= symbol_size):\n",
    "                messages[i] = torch.hstack((messages[i], tensor(0).to(device)))\n",
    "            textfile.write(str(messages[i]) + \"\\n\")\n",
    "        textfile.close()\n",
    "        topsim = language_analysis.TopographicSimilarity.compute_topsim(torch.stack(sender_inputs).detach().cpu(),\n",
    "                                                                        torch.stack(messages).detach().cpu(), 'hamming',\n",
    "                                                                        'hamming')\n",
    "        bosdis = analysis.bosdis(torch.stack(sender_inputs), torch.stack(messages), opts.vocab_size)\n",
    "        posdis = analysis.posdis(torch.stack(sender_inputs), torch.stack(messages))\n",
    "        mi = mutual_info(sender_inputs, messages)\n",
    "        output_mess = open(f'./msgs/{opts.perceptual_dimensions}.pickle', 'wb')\n",
    "        pickle.dump({'messages': messages}, output_mess)\n",
    "        pickle.dump({'objects': sender_inputs}, output_mess)\n",
    "            \n",
    "        print(f\"entropy sender inputs {entropy(sender_inputs)}\")\n",
    "        print(f\"mi sender inputs msgs {mi}\")\n",
    "        print(f\"bosdis {bosdis}\")\n",
    "        print(f\"posdis {posdis}\")\n",
    "        print(f\"topsim {topsim}\")\n",
    "\n",
    "        if opts.dump_msg_folder:\n",
    "            opts.dump_msg_folder.mkdir(exist_ok=True)\n",
    "            msg_dict = {}\n",
    "\n",
    "            output_msg = (\n",
    "                f\"messages_{opts.perceptual_dimensions}_vocab_{opts.vocab_size}\"\n",
    "                f\"_maxlen_{symbol_size}_bsize_{opts.batch_size}\"\n",
    "                f\"_n_distractors_{opts.n_distractors}_train_size_{opts.train_samples}\"\n",
    "                f\"_valid_size_{opts.validation_samples}_test_size_{opts.test_samples}\"\n",
    "                f\"_slr_{opts.sender_lr}_rlr_{opts.receiver_lr}_shidden_{opts.sender_hidden}\"\n",
    "                f\"_rhidden_{opts.receiver_hidden}_semb_{opts.sender_embedding}\"\n",
    "                f\"_remb_{opts.receiver_embedding}_mode_{opts.mode}\"\n",
    "                f\"_scell_{opts.sender_cell}_rcell_{opts.receiver_cell}.msg\"\n",
    "            )\n",
    "\n",
    "            output_file = opts.dump_msg_folder / output_msg\n",
    "            with open(output_file, \"w\") as f:\n",
    "                f.write(f\"{opts}\\n\")\n",
    "                for (\n",
    "                        sender_input,\n",
    "                        message,\n",
    "                        receiver_input,\n",
    "                        receiver_output,\n",
    "                        label,\n",
    "                ) in zip(\n",
    "                    sender_inputs, messages, receiver_inputs, receiver_outputs, labels\n",
    "                ):\n",
    "                    sender_input = \",\".join(map(str, sender_input.tolist()))\n",
    "                    message = \",\".join(map(str, message.tolist()))\n",
    "                    distractors_list = receiver_input.tolist()\n",
    "                    receiver_input = \"; \".join(\n",
    "                        [\",\".join(map(str, elem)) for elem in distractors_list]\n",
    "                    )\n",
    "                    if is_gs:\n",
    "                        receiver_output = receiver_output.argmax()\n",
    "                    f.write(\n",
    "                        f\"{sender_input} -> {receiver_input} -> {message} -> {receiver_output} (label={label.item()})\\n\"\n",
    "                    )\n",
    "\n",
    "                    if message in msg_dict:\n",
    "                        msg_dict[message] += 1\n",
    "                    else:\n",
    "                        msg_dict[message] = 1\n",
    "\n",
    "                sorted_msgs = sorted(\n",
    "                    msg_dict.items(), key=operator.itemgetter(1), reverse=True\n",
    "                )\n",
    "                f.write(\n",
    "                    f\"\\nUnique target vectors seen by sender: {len(unique_dict.keys())}\\n\"\n",
    "                )\n",
    "                f.write(f\"Unique messages produced by sender: {len(msg_dict.keys())}\\n\")\n",
    "                f.write(f\"Messagses: 'msg' : msg_count: {str(sorted_msgs)}\\n\")\n",
    "                f.write(f\"\\nAccuracy: {accuracy}\")\n",
    "\n",
    "    print('saving listener model as:', listener_path)\n",
    "    save_model(receiver, listener_path)\n",
    "    print('saving speaker model as:', speaker_path)\n",
    "    save_model(sender, speaker_path)\n",
    "    return accuracy, posdis, bosdis, topsim, mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd3dee79-6f2a-4707-b453-49f67bed59ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict2string(d):\n",
    "    \"\"\"\n",
    "    Convert a dict d to string s\n",
    "    :param d: Dictionary object?\n",
    "    :return s: a string of all the elements in a dict\n",
    "    \"\"\"\n",
    "    s = []\n",
    "\n",
    "    for k, v in d.items():\n",
    "        if type(v) in (int, float):\n",
    "            s.append(f\"--{k}={v}\")\n",
    "        elif type(v) is bool and v:\n",
    "            s.append(f\"--{k}\")\n",
    "        elif type(v) is str:\n",
    "            assert (\n",
    "                '\"' not in v\n",
    "            ), f\"Key {k} has string value {v} which contains forbidden quotes.\"\n",
    "            s.append(f\"--{k}={v}\")\n",
    "        else:\n",
    "            raise Exception(f\"Key {k} has value {v} of unsupported type {type(v)}.\")\n",
    "            # print(s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def get_dims(features=5, feature_dim=6, random=False):\n",
    "    \"\"\"\n",
    "    Generate a feature vector for n features and k feature dimensions\n",
    "    :param features: How many features should an object have?\n",
    "    :param agent_type: How many dimension should a single feature have?\n",
    "    :return dims: A feature vector of n features X k feature dimension, example: n = 3, k = 5 -> dims: [0, 3, 2]\n",
    "    \"\"\"\n",
    "    dims = [None] * features\n",
    "    if random:\n",
    "        for feature in range(0,features):\n",
    "            dims[feature] = random.randrange(1, feature_dim)\n",
    "    else:\n",
    "        dims = [feature_dim] * features\n",
    "    return dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6630399f-c06d-4045-be68-eddd8a6ae1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(module, path):\n",
    "    \"\"\"\n",
    "    https://pytorch.org/tutorials/beginner/saving_loading_models.html#what-is-a-state-dict\n",
    "    \"\"\"\n",
    "    state_dict = module.agent.state_dict()\n",
    "    torch.save(state_dict, path)\n",
    "    print('--Saving complete--')\n",
    "    \n",
    "    \n",
    "def load_model(module, path):\n",
    "    state_dict = torch.load(path)\n",
    "    return state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dafb5a66-3e43-48fc-9b95-20bfbbf8f6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment params\n",
    "vocab_size = 500\n",
    "random_seed = 0\n",
    "n_epoch = 20\n",
    "batch_size = 64\n",
    "n_distractors = 3\n",
    "dims = get_dims(features=3, feature_dim=7)\n",
    "perceptual_dimensions = str(dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bdf7285-a9b5-4593-86a8-c32af868a3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 0\n",
    "\n",
    "exp_params = dict(\n",
    "    vocab_size=vocab_size,\n",
    "    random_seed=random_seed,\n",
    "    n_epoch=n_epoch,\n",
    "    batch_size=batch_size,\n",
    "    n_distractors=n_distractors,\n",
    "    perceptual_dimensions=str(dims),\n",
    "    max_len = 5,\n",
    "    dump_msg_folder = 'dump',\n",
    "    train_samples = 5000,\n",
    "    test_samples = 2000,\n",
    "    validation_samples = 2000,\n",
    "    sender_hidden = 300,\n",
    "    receiver_hidden = 300,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0abe4b6-84f8-4d2d-96e0-c4459bc1db8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paramstring(vocab_size = 500,\n",
    "               random_seed = 0,\n",
    "               n_epoch = 50,\n",
    "               batch_size = 64,\n",
    "               n_distractors = 9,\n",
    "               dims = [4, 4]):\n",
    "    \n",
    "    dims_constr = get_dims(features=dims[0], feature_dim=dims[1]),\n",
    "    perceptual_dimensions = str(dims_constr[0])\n",
    "\n",
    "    exp_params = dict(\n",
    "        vocab_size=vocab_size,\n",
    "        random_seed=random_seed,\n",
    "        n_epoch=n_epoch,\n",
    "        batch_size=batch_size,\n",
    "        n_distractors=n_distractors,\n",
    "        perceptual_dimensions=perceptual_dimensions,\n",
    "        max_len = 5,\n",
    "        dump_msg_folder = 'dump',\n",
    "        train_samples = 4000,\n",
    "        test_samples = 1000,\n",
    "        validation_samples = 1000,\n",
    "        sender_hidden = 300,\n",
    "        receiver_hidden = 300,\n",
    "    )\n",
    "    \n",
    "    params = dict2string(exp_params)\n",
    "    return params\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa219e9-ac1e-4234-a9f5-ca38abd51e37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2]\n",
      "randseed: 67\n",
      "Cannot yet compute \"smart\" baseline value for messages of length greater than 1\n",
      "{\"loss\": 2.099583148956299, \"acc\": 0.19062499701976776, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 1}\n",
      "{\"loss\": 1.8266143798828125, \"acc\": 0.20000000298023224, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 2}\n",
      "{\"loss\": 0.7702405452728271, \"acc\": 0.609375, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 3}\n",
      "{\"loss\": 0.4007873237133026, \"acc\": 0.7802083492279053, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 4}\n",
      "{\"loss\": 0.3154848515987396, \"acc\": 0.8802083134651184, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 5}\n",
      "{\"loss\": 0.2195562869310379, \"acc\": 0.8770833611488342, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 6}\n",
      "{\"loss\": 0.14935627579689026, \"acc\": 0.9166666865348816, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 7}\n",
      "{\"loss\": 0.22628207504749298, \"acc\": 0.8770833611488342, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 8}\n",
      "{\"loss\": 0.13096323609352112, \"acc\": 0.9197916388511658, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 9}\n",
      "{\"loss\": 0.14442852139472961, \"acc\": 0.9166666865348816, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 10}\n",
      "{\"loss\": 0.12992297112941742, \"acc\": 0.9197916388511658, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 11}\n",
      "{\"loss\": 0.11397222429513931, \"acc\": 0.9197916388511658, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 12}\n",
      "{\"loss\": 0.11198141425848007, \"acc\": 0.9197916388511658, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 13}\n",
      "{\"loss\": 0.11280844360589981, \"acc\": 0.9166666865348816, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 14}\n",
      "{\"loss\": 0.11185398697853088, \"acc\": 0.9312499761581421, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 15}\n",
      "{\"loss\": 0.10832302272319794, \"acc\": 0.9312499761581421, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 16}\n",
      "{\"loss\": 0.11056540161371231, \"acc\": 0.9312499761581421, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 17}\n",
      "{\"loss\": 0.10889240354299545, \"acc\": 0.9312499761581421, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 18}\n",
      "{\"loss\": 0.10954207926988602, \"acc\": 0.9166666865348816, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 19}\n",
      "{\"loss\": 0.12777188420295715, \"acc\": 0.9166666865348816, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 20}\n",
      "{\"loss\": 0.4802570939064026, \"acc\": 0.75, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 21}\n",
      "{\"loss\": 0.19498945772647858, \"acc\": 0.8833333253860474, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 22}\n",
      "{\"loss\": 0.2504779100418091, \"acc\": 0.8864583373069763, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 23}\n",
      "{\"loss\": 0.17129310965538025, \"acc\": 0.9020833373069763, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 24}\n",
      "{\"loss\": 0.15655076503753662, \"acc\": 0.9020833373069763, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 25}\n",
      "{\"loss\": 0.15376541018486023, \"acc\": 0.9020833373069763, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 26}\n",
      "{\"loss\": 0.1546945422887802, \"acc\": 0.9020833373069763, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 27}\n",
      "{\"loss\": 0.15734797716140747, \"acc\": 0.9020833373069763, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 28}\n",
      "{\"loss\": 0.11287694424390793, \"acc\": 0.9260416626930237, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 29}\n",
      "{\"loss\": 0.11019978672266006, \"acc\": 0.9260416626930237, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 30}\n",
      "{\"loss\": 0.10882720351219177, \"acc\": 0.9260416626930237, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 31}\n",
      "{\"loss\": 0.10884983837604523, \"acc\": 0.9229166507720947, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 32}\n",
      "{\"loss\": 0.11986958980560303, \"acc\": 0.9260416626930237, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 33}\n",
      "{\"loss\": 0.11055223643779755, \"acc\": 0.9260416626930237, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 34}\n",
      "{\"loss\": 0.1567555069923401, \"acc\": 0.9020833373069763, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 35}\n",
      "{\"loss\": 0.10849004238843918, \"acc\": 0.9229166507720947, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 36}\n",
      "{\"loss\": 0.11500079184770584, \"acc\": 0.9260416626930237, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 37}\n",
      "{\"loss\": 0.10971121490001678, \"acc\": 0.9260416626930237, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 38}\n",
      "{\"loss\": 0.7897435426712036, \"acc\": 0.653124988079071, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 39}\n",
      "{\"loss\": 0.4979337751865387, \"acc\": 0.731249988079071, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 40}\n",
      "{\"loss\": 0.4181419312953949, \"acc\": 0.828125, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 41}\n",
      "{\"loss\": 0.3079231381416321, \"acc\": 0.8427083492279053, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 42}\n",
      "{\"loss\": 0.29374411702156067, \"acc\": 0.824999988079071, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 43}\n",
      "{\"loss\": 0.2758319675922394, \"acc\": 0.846875011920929, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 44}\n",
      "{\"loss\": 0.2620607316493988, \"acc\": 0.8218749761581421, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 45}\n",
      "{\"loss\": 0.2505055069923401, \"acc\": 0.8645833134651184, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 46}\n",
      "{\"loss\": 0.2704423666000366, \"acc\": 0.828125, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 47}\n",
      "{\"loss\": 0.2519609034061432, \"acc\": 0.8395833373069763, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 48}\n",
      "{\"loss\": 0.25199398398399353, \"acc\": 0.828125, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 49}\n",
      "{\"loss\": 0.24369744956493378, \"acc\": 0.8395833373069763, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 50}\n",
      "| Accuracy on test set: 0.8447917103767395\n",
      "| Entropy for each dimension of the input vectors = [0.9994708218806826, 0.9999968691491221, 0.9986188549650421, 0.9994708218806826]\n",
      "| H(msg) = 3.468315708030311\n",
      "| MI = [0.4834, 0.8598, 0.7175, 0.7372]\n",
      "entropy sender inputs 3.984406748970855\n",
      "mi sender inputs msgs 3.4683157080303104\n",
      "bosdis 0.1398833990097046\n",
      "posdis 0.013454444706439972\n",
      "topsim 0.2812023120186597\n",
      "saving listener model as: ./models/listener.pt\n",
      "--Saving complete--\n",
      "saving speaker model as: ./models/speaker.pt\n",
      "--Saving complete--\n",
      "accurracy between sender and receiver : 0.8447917103767395\n",
      "[3, 3, 3, 3]\n",
      "randseed: 8189\n",
      "Cannot yet compute \"smart\" baseline value for messages of length greater than 1\n",
      "loading model for speaker\n",
      "loading model for listener\n",
      "{\"loss\": 1.5465538501739502, \"acc\": 0.3739583194255829, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 1}\n",
      "{\"loss\": 1.0323140621185303, \"acc\": 0.6156250238418579, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 2}\n",
      "{\"loss\": 0.5180655717849731, \"acc\": 0.7770833373069763, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 3}\n",
      "{\"loss\": 0.40420669317245483, \"acc\": 0.8385416865348816, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 4}\n",
      "{\"loss\": 0.4302326738834381, \"acc\": 0.809374988079071, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 5}\n",
      "{\"loss\": 0.34656277298927307, \"acc\": 0.8791666626930237, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 6}\n",
      "{\"loss\": 0.30140915513038635, \"acc\": 0.8854166865348816, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 7}\n",
      "{\"loss\": 0.2605099678039551, \"acc\": 0.9020833373069763, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 8}\n",
      "{\"loss\": 0.2772705852985382, \"acc\": 0.9208333492279053, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 9}\n",
      "{\"loss\": 0.23752155900001526, \"acc\": 0.9239583611488342, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 10}\n",
      "{\"loss\": 0.22802117466926575, \"acc\": 0.9312499761581421, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 11}\n",
      "{\"loss\": 0.24864639341831207, \"acc\": 0.9177083373069763, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 12}\n",
      "{\"loss\": 0.2566083073616028, \"acc\": 0.8989583253860474, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 13}\n",
      "{\"loss\": 0.22126223146915436, \"acc\": 0.9229166507720947, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 14}\n",
      "{\"loss\": 0.2218748778104782, \"acc\": 0.9364583492279053, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 15}\n",
      "{\"loss\": 0.2400350123643875, \"acc\": 0.909375011920929, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 16}\n",
      "{\"loss\": 0.24110206961631775, \"acc\": 0.9114583134651184, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 17}\n",
      "{\"loss\": 0.19262374937534332, \"acc\": 0.9437500238418579, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 18}\n",
      "{\"loss\": 0.3931910991668701, \"acc\": 0.8385416865348816, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 19}\n",
      "{\"loss\": 0.25953489542007446, \"acc\": 0.8958333134651184, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 20}\n",
      "{\"loss\": 0.22285166382789612, \"acc\": 0.918749988079071, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 21}\n",
      "{\"loss\": 0.22470273077487946, \"acc\": 0.9072916507720947, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 22}\n",
      "{\"loss\": 0.24340732395648956, \"acc\": 0.9072916507720947, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 23}\n",
      "{\"loss\": 0.2871895134449005, \"acc\": 0.887499988079071, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 24}\n",
      "{\"loss\": 0.25617972016334534, \"acc\": 0.8968750238418579, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 25}\n",
      "{\"loss\": 0.21313469111919403, \"acc\": 0.9197916388511658, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 26}\n",
      "{\"loss\": 0.18906906247138977, \"acc\": 0.9312499761581421, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 27}\n",
      "{\"loss\": 0.20395587384700775, \"acc\": 0.925000011920929, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 28}\n",
      "{\"loss\": 0.18465083837509155, \"acc\": 0.9437500238418579, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 29}\n",
      "{\"loss\": 0.15936866402626038, \"acc\": 0.9520833492279053, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 30}\n",
      "{\"loss\": 0.15751555562019348, \"acc\": 0.9614583253860474, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 31}\n",
      "{\"loss\": 0.19513100385665894, \"acc\": 0.9375, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 32}\n",
      "{\"loss\": 0.19934286177158356, \"acc\": 0.9322916865348816, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 33}\n",
      "{\"loss\": 0.21778500080108643, \"acc\": 0.9281250238418579, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 34}\n",
      "{\"loss\": 0.16838428378105164, \"acc\": 0.9458333253860474, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 35}\n",
      "{\"loss\": 0.13651227951049805, \"acc\": 0.9645833373069763, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 36}\n",
      "{\"loss\": 0.16012847423553467, \"acc\": 0.9520833492279053, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 37}\n",
      "{\"loss\": 0.16715675592422485, \"acc\": 0.9354166388511658, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 38}\n",
      "{\"loss\": 0.12370527535676956, \"acc\": 0.9666666388511658, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 39}\n",
      "{\"loss\": 0.1613282710313797, \"acc\": 0.9427083134651184, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 40}\n",
      "{\"loss\": 0.1825222373008728, \"acc\": 0.925000011920929, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 41}\n",
      "{\"loss\": 0.12852168083190918, \"acc\": 0.9645833373069763, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 42}\n",
      "{\"loss\": 0.20192870497703552, \"acc\": 0.9281250238418579, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 43}\n",
      "{\"loss\": 0.1635497361421585, \"acc\": 0.9395833611488342, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 44}\n",
      "{\"loss\": 0.14658251404762268, \"acc\": 0.9447916746139526, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 45}\n",
      "{\"loss\": 0.17524249851703644, \"acc\": 0.940625011920929, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 46}\n",
      "{\"loss\": 0.19007617235183716, \"acc\": 0.9197916388511658, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 47}\n",
      "{\"loss\": 0.2426546812057495, \"acc\": 0.9104166626930237, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 48}\n",
      "{\"loss\": 0.20056933164596558, \"acc\": 0.9177083373069763, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 49}\n",
      "{\"loss\": 0.14765432476997375, \"acc\": 0.9437500238418579, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 50}\n",
      "| Accuracy on test set: 0.9385417103767395\n",
      "| Entropy for each dimension of the input vectors = [1.5825677867708412, 1.584789344654321, 1.583604638718366, 1.5819425390597137]\n",
      "| H(msg) = 5.801622219084292\n",
      "| MI = [1.2241, 1.445, 1.414, 1.2551]\n",
      "entropy sender inputs 6.266304528141694\n",
      "mi sender inputs msgs 5.801622219084292\n",
      "bosdis 0.052440445870161057\n",
      "posdis 0.042317695915699005\n",
      "topsim 0.2702497485401347\n",
      "saving listener model as: ./models/listener.pt\n",
      "--Saving complete--\n",
      "saving speaker model as: ./models/speaker.pt\n",
      "--Saving complete--\n",
      "accurracy between sender and receiver : 0.9385417103767395\n",
      "[4, 4, 4, 4]\n",
      "randseed: 3404\n",
      "Cannot yet compute \"smart\" baseline value for messages of length greater than 1\n",
      "loading model for speaker\n",
      "loading model for listener\n",
      "{\"loss\": 1.5323150157928467, \"acc\": 0.36250001192092896, \"length\": 3.754166603088379, \"mode\": \"test\", \"epoch\": 1}\n",
      "{\"loss\": 1.0382241010665894, \"acc\": 0.609375, \"length\": 5.387499809265137, \"mode\": \"test\", \"epoch\": 2}\n",
      "{\"loss\": 0.6940352916717529, \"acc\": 0.7104166746139526, \"length\": 5.820833206176758, \"mode\": \"test\", \"epoch\": 3}\n",
      "{\"loss\": 0.523987352848053, \"acc\": 0.778124988079071, \"length\": 5.790625095367432, \"mode\": \"test\", \"epoch\": 4}\n",
      "{\"loss\": 0.3979007303714752, \"acc\": 0.8052083253860474, \"length\": 5.714583396911621, \"mode\": \"test\", \"epoch\": 5}\n",
      "{\"loss\": 0.3521419167518616, \"acc\": 0.8510416746139526, \"length\": 5.796875, \"mode\": \"test\", \"epoch\": 6}\n",
      "{\"loss\": 0.2812650799751282, \"acc\": 0.8770833611488342, \"length\": 5.813541889190674, \"mode\": \"test\", \"epoch\": 7}\n",
      "{\"loss\": 0.2592538297176361, \"acc\": 0.8885416388511658, \"length\": 5.785416603088379, \"mode\": \"test\", \"epoch\": 8}\n",
      "{\"loss\": 0.24016384780406952, \"acc\": 0.90625, \"length\": 5.429166793823242, \"mode\": \"test\", \"epoch\": 9}\n",
      "{\"loss\": 0.21721969544887543, \"acc\": 0.9145833253860474, \"length\": 5.665625095367432, \"mode\": \"test\", \"epoch\": 10}\n",
      "{\"loss\": 0.27921855449676514, \"acc\": 0.8697916865348816, \"length\": 5.772916793823242, \"mode\": \"test\", \"epoch\": 11}\n",
      "{\"loss\": 0.20434275269508362, \"acc\": 0.9239583611488342, \"length\": 5.751041889190674, \"mode\": \"test\", \"epoch\": 12}\n",
      "{\"loss\": 0.2593545615673065, \"acc\": 0.8864583373069763, \"length\": 5.846875190734863, \"mode\": \"test\", \"epoch\": 13}\n",
      "{\"loss\": 0.22578388452529907, \"acc\": 0.8958333134651184, \"length\": 5.584374904632568, \"mode\": \"test\", \"epoch\": 14}\n",
      "{\"loss\": 0.18406641483306885, \"acc\": 0.9364583492279053, \"length\": 5.6739583015441895, \"mode\": \"test\", \"epoch\": 15}\n",
      "{\"loss\": 0.192693829536438, \"acc\": 0.9291666746139526, \"length\": 5.619791507720947, \"mode\": \"test\", \"epoch\": 16}\n",
      "{\"loss\": 0.20424334704875946, \"acc\": 0.9156249761581421, \"length\": 5.7520833015441895, \"mode\": \"test\", \"epoch\": 17}\n",
      "{\"loss\": 0.2357383519411087, \"acc\": 0.8968750238418579, \"length\": 5.852083206176758, \"mode\": \"test\", \"epoch\": 18}\n",
      "{\"loss\": 0.23137135803699493, \"acc\": 0.9135416746139526, \"length\": 5.6270833015441895, \"mode\": \"test\", \"epoch\": 19}\n",
      "{\"loss\": 0.3095645010471344, \"acc\": 0.8645833134651184, \"length\": 5.145833492279053, \"mode\": \"test\", \"epoch\": 20}\n",
      "{\"loss\": 0.24141621589660645, \"acc\": 0.9145833253860474, \"length\": 5.059374809265137, \"mode\": \"test\", \"epoch\": 21}\n",
      "{\"loss\": 0.22134794294834137, \"acc\": 0.9041666388511658, \"length\": 5.632291793823242, \"mode\": \"test\", \"epoch\": 22}\n",
      "{\"loss\": 0.24706310033798218, \"acc\": 0.8843749761581421, \"length\": 5.824999809265137, \"mode\": \"test\", \"epoch\": 23}\n",
      "{\"loss\": 0.27272433042526245, \"acc\": 0.8927083611488342, \"length\": 5.682291507720947, \"mode\": \"test\", \"epoch\": 24}\n",
      "{\"loss\": 0.23654791712760925, \"acc\": 0.9052083492279053, \"length\": 5.727083206176758, \"mode\": \"test\", \"epoch\": 25}\n",
      "{\"loss\": 0.1948232799768448, \"acc\": 0.925000011920929, \"length\": 5.661458492279053, \"mode\": \"test\", \"epoch\": 26}\n",
      "{\"loss\": 0.23023703694343567, \"acc\": 0.9010416865348816, \"length\": 5.738541603088379, \"mode\": \"test\", \"epoch\": 27}\n",
      "{\"loss\": 0.17557215690612793, \"acc\": 0.9437500238418579, \"length\": 5.661458492279053, \"mode\": \"test\", \"epoch\": 28}\n",
      "{\"loss\": 0.1996667981147766, \"acc\": 0.918749988079071, \"length\": 5.864583492279053, \"mode\": \"test\", \"epoch\": 29}\n",
      "{\"loss\": 0.21425041556358337, \"acc\": 0.9052083492279053, \"length\": 5.336458206176758, \"mode\": \"test\", \"epoch\": 30}\n",
      "{\"loss\": 0.23351868987083435, \"acc\": 0.8885416388511658, \"length\": 5.479166507720947, \"mode\": \"test\", \"epoch\": 31}\n",
      "{\"loss\": 0.18809659779071808, \"acc\": 0.9312499761581421, \"length\": 5.3770833015441895, \"mode\": \"test\", \"epoch\": 32}\n",
      "{\"loss\": 0.2179371416568756, \"acc\": 0.8947916626930237, \"length\": 5.340624809265137, \"mode\": \"test\", \"epoch\": 33}\n",
      "{\"loss\": 0.2636474370956421, \"acc\": 0.8864583373069763, \"length\": 5.863541603088379, \"mode\": \"test\", \"epoch\": 34}\n",
      "{\"loss\": 0.1767193228006363, \"acc\": 0.9312499761581421, \"length\": 5.917708396911621, \"mode\": \"test\", \"epoch\": 35}\n",
      "{\"loss\": 0.2448904812335968, \"acc\": 0.903124988079071, \"length\": 5.827083110809326, \"mode\": \"test\", \"epoch\": 36}\n",
      "{\"loss\": 0.2044350951910019, \"acc\": 0.921875, \"length\": 5.704166889190674, \"mode\": \"test\", \"epoch\": 37}\n",
      "{\"loss\": 0.1637791097164154, \"acc\": 0.9385416507720947, \"length\": 5.914583206176758, \"mode\": \"test\", \"epoch\": 38}\n",
      "{\"loss\": 0.2485167533159256, \"acc\": 0.8822916746139526, \"length\": 5.900000095367432, \"mode\": \"test\", \"epoch\": 39}\n",
      "{\"loss\": 0.20806020498275757, \"acc\": 0.9114583134651184, \"length\": 5.996874809265137, \"mode\": \"test\", \"epoch\": 40}\n",
      "{\"loss\": 0.2149609625339508, \"acc\": 0.9145833253860474, \"length\": 5.8729166984558105, \"mode\": \"test\", \"epoch\": 41}\n",
      "{\"loss\": 0.18177835643291473, \"acc\": 0.9260416626930237, \"length\": 5.823958396911621, \"mode\": \"test\", \"epoch\": 42}\n",
      "{\"loss\": 0.18573276698589325, \"acc\": 0.9302083253860474, \"length\": 5.875, \"mode\": \"test\", \"epoch\": 43}\n",
      "{\"loss\": 0.17922379076480865, \"acc\": 0.9312499761581421, \"length\": 5.903124809265137, \"mode\": \"test\", \"epoch\": 44}\n",
      "{\"loss\": 0.22576285898685455, \"acc\": 0.903124988079071, \"length\": 5.9375, \"mode\": \"test\", \"epoch\": 45}\n",
      "{\"loss\": 0.1896451711654663, \"acc\": 0.918749988079071, \"length\": 5.930208206176758, \"mode\": \"test\", \"epoch\": 46}\n",
      "{\"loss\": 0.18733584880828857, \"acc\": 0.9135416746139526, \"length\": 5.949999809265137, \"mode\": \"test\", \"epoch\": 47}\n",
      "{\"loss\": 0.17097997665405273, \"acc\": 0.9333333373069763, \"length\": 5.940625190734863, \"mode\": \"test\", \"epoch\": 48}\n",
      "{\"loss\": 0.15908183157444, \"acc\": 0.9479166865348816, \"length\": 5.894791603088379, \"mode\": \"test\", \"epoch\": 49}\n",
      "{\"loss\": 0.15789060294628143, \"acc\": 0.9458333253860474, \"length\": 5.764583110809326, \"mode\": \"test\", \"epoch\": 50}\n",
      "| Accuracy on test set: 0.9239583611488342\n",
      "| Entropy for each dimension of the input vectors = [1.9987761370067223, 1.9996075556060176, 1.9987977421612424, 1.9981068314524488]\n",
      "| H(msg) = 6.887128468844577\n",
      "| MI = [1.2876, 1.4608, 1.4816, 1.3219]\n",
      "entropy sender inputs 7.809057957727458\n",
      "mi sender inputs msgs 6.887128468844577\n",
      "bosdis 0.05776458606123924\n",
      "posdis 0.015474731102585793\n",
      "topsim 0.19500267596862902\n",
      "saving listener model as: ./models/listener.pt\n",
      "--Saving complete--\n",
      "saving speaker model as: ./models/speaker.pt\n",
      "--Saving complete--\n",
      "accurracy between sender and receiver : 0.9239583611488342\n",
      "[5, 5, 5, 5]\n",
      "randseed: 4544\n",
      "Cannot yet compute \"smart\" baseline value for messages of length greater than 1\n",
      "loading model for speaker\n",
      "loading model for listener\n",
      "{\"loss\": 1.3699026107788086, \"acc\": 0.43541666865348816, \"length\": 3.9312500953674316, \"mode\": \"test\", \"epoch\": 1}\n",
      "{\"loss\": 0.64719557762146, \"acc\": 0.721875011920929, \"length\": 4.581250190734863, \"mode\": \"test\", \"epoch\": 2}\n",
      "{\"loss\": 0.4981003999710083, \"acc\": 0.7895833253860474, \"length\": 4.596875190734863, \"mode\": \"test\", \"epoch\": 3}\n",
      "{\"loss\": 0.42037761211395264, \"acc\": 0.8135416507720947, \"length\": 4.865624904632568, \"mode\": \"test\", \"epoch\": 4}\n",
      "{\"loss\": 0.3706507682800293, \"acc\": 0.8374999761581421, \"length\": 5.040625095367432, \"mode\": \"test\", \"epoch\": 5}\n",
      "{\"loss\": 0.2897278666496277, \"acc\": 0.8760416507720947, \"length\": 5.168749809265137, \"mode\": \"test\", \"epoch\": 6}\n",
      "{\"loss\": 0.34139370918273926, \"acc\": 0.8541666865348816, \"length\": 5.114583492279053, \"mode\": \"test\", \"epoch\": 7}\n",
      "{\"loss\": 0.3169223666191101, \"acc\": 0.8552083373069763, \"length\": 5.221875190734863, \"mode\": \"test\", \"epoch\": 8}\n",
      "{\"loss\": 0.35558581352233887, \"acc\": 0.8427083492279053, \"length\": 5.1895833015441895, \"mode\": \"test\", \"epoch\": 9}\n",
      "{\"loss\": 0.30255720019340515, \"acc\": 0.8614583611488342, \"length\": 5.261458396911621, \"mode\": \"test\", \"epoch\": 10}\n",
      "{\"loss\": 0.2491433471441269, \"acc\": 0.8927083611488342, \"length\": 5.210416793823242, \"mode\": \"test\", \"epoch\": 11}\n",
      "{\"loss\": 0.3314686417579651, \"acc\": 0.846875011920929, \"length\": 4.46875, \"mode\": \"test\", \"epoch\": 12}\n",
      "{\"loss\": 0.28986266255378723, \"acc\": 0.8552083373069763, \"length\": 4.4979166984558105, \"mode\": \"test\", \"epoch\": 13}\n",
      "{\"loss\": 0.3607613444328308, \"acc\": 0.840624988079071, \"length\": 4.730208396911621, \"mode\": \"test\", \"epoch\": 14}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def emergent_communication(meaning_space, symbol_size=5, conversation_rounds=10, experiments=30):\n",
    "    dims = [2, 3, 4, 5, 6, 7, 10, 15, 20, 30]\n",
    "    for experiment in range(experiments):\n",
    "        accs = []\n",
    "        training_accs = {}\n",
    "        for conversation_round in range(conversation_rounds):\n",
    "            meaning_space[1] = dims[conversation_round] # Make meaning space larger\n",
    "            parameters = get_paramstring(dims=meaning_space)\n",
    "            start = True if conversation_round == 0 else False\n",
    "            acc, posdis, bosdis, topsim, MI = main(parameters, symbol_size, start=start)\n",
    "            print(f'accurracy between sender and receiver : {acc}' )\n",
    "\n",
    "            training_accs[f'{conversation_round}_acc'] = acc\n",
    "            training_accs[f'{conversation_round}_posdis'] = posdis\n",
    "            training_accs[f'{conversation_round}_bosdis'] = bosdis\n",
    "            training_accs[f'{conversation_round}_topsim'] = topsim\n",
    "            training_accs[f'{conversation_round}_MI'] = MI\n",
    "            accs.append(acc)\n",
    "            \n",
    "        with open(f'accs_2/exp_{experiment+29}.json', 'w') as exp_file:\n",
    "             exp_file.write(json.dumps(training_accs))\n",
    "    return accs\n",
    "\n",
    "\n",
    "meaning_space = [4, 2]\n",
    "emergent_communication(meaning_space, symbol_size=5, conversation_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c58655a-6dab-4e90-a45c-e2f1182c3177",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
